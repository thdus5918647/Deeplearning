{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200\n",
      "    constraint    mobility capability context  y\n",
      "0  BEST_EFFORT  STATIONARY        LOW    TEXT  1\n",
      "1        DELAY  STATIONARY        LOW    TEXT  1\n",
      "2  RELIABILITY  STATIONARY        LOW    TEXT  1\n",
      "3  BEST_EFFORT  STATIONARY     MEDIUM    TEXT  3\n",
      "4        DELAY  STATIONARY     MEDIUM    TEXT  1\n",
      "상태:\n",
      "[1 3 2 4]\n",
      "[['BEST_EFFORT' 'STATIONARY' 'LOW' 'TEXT']\n",
      " ['DELAY' 'STATIONARY' 'LOW' 'TEXT']\n",
      " ['RELIABILITY' 'STATIONARY' 'LOW' 'TEXT']\n",
      " ['BEST_EFFORT' 'STATIONARY' 'MEDIUM' 'TEXT']\n",
      " ['DELAY' 'STATIONARY' 'MEDIUM' 'TEXT']]\n",
      "[1 1 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('data.csv', encoding='latin1')\n",
    "\n",
    "print(len(data))\n",
    "print(data[:5])\n",
    "print(\"상태:\",data[\"y\"].unique(),sep=\"\\n\")\n",
    "\n",
    "data_X = data[['constraint','mobility','capability','context']].values\n",
    "data_y = data['y'].values\n",
    "\n",
    "print(data_X[:5])\n",
    "print(data_y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터를 8:2로 나누고, 데이터의 순서 또한 섞음\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(data_X, data_y, train_size=0.8, random_state = 1)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터에 대해 원-핫 인코딩\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print(y_train[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
